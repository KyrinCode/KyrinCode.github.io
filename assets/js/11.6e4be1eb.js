(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{460:function(t,a,n){t.exports=n.p+"assets/img/network.e61eba08.png"},461:function(t,a,n){t.exports=n.p+"assets/img/upsample.01444aeb.png"},578:function(t,a,n){"use strict";n.r(a);var s=n(4),e=Object(s.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("p",[t._v("博一《深度学习》课程论文选读：PointRend（图像分割）阅读报告")]),t._v(" "),s("h2",{attrs:{id:"论文介绍"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#论文介绍"}},[t._v("#")]),t._v(" 论文介绍")]),t._v(" "),s("p",[t._v("本次论文阅读选择的是图像分割领域很新的一篇文章 PointRend。论文全称：PointRend: Image Segmentation as Rendering，是何凯明的又一力作。作者从图像渲染的角度出发，提出了一种快速高效的图像分割算法。")]),t._v(" "),s("p",[t._v("论文地址："),s("a",{attrs:{href:"https://arxiv.org/abs/1912.08193",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://arxiv.org/abs/1912.08193"),s("OutboundLink")],1)]),t._v(" "),s("h2",{attrs:{id:"问题背景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题背景"}},[t._v("#")]),t._v(" 问题背景")]),t._v(" "),s("p",[t._v("图像分割（Image Segmentation）就是：将数字图像按照语义信息分割成多个图像子区域。计算机视觉领域，图像分割是一个很有前景且很重要的方向，在更多的任务中如人脸识别、交通控制、卫星定位等都会有对图像分割的需求。当前，基于深度学习的图像分割方法已经达到了很不错的效果。")]),t._v(" "),s("p",[t._v("之前的 Mask R-CNN 方法，已经有了比较出色的效果。但是图像分割算法当前遇到的主要问题就是物体的边缘难以处理。这篇文章提出的 PointRend 实现了以更低的算力得到更细粒度的分割效果。")]),t._v(" "),s("h2",{attrs:{id:"算法贡献"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#算法贡献"}},[t._v("#")]),t._v(" 算法贡献")]),t._v(" "),s("p",[t._v("3D 图像的渲染与图像分割面领着同样的问题，即物体的边缘难以处理。依此为灵感，图像分割模型最容易误判的位置就是物体的边缘，那么就用类似渲染的方式将处理的最不确定的像素点（集中在高频区域）。总体上是一个迭代上采样的过程，网络结构如下：")]),t._v(" "),s("img",{staticStyle:{zoom:"65%"},attrs:{src:n(460),alt:"network"}}),t._v(" "),s("p",[t._v("在输出分片率达到图片分辨率之前，循环进行如下操作：")]),t._v(" "),s("ol",[s("li",[t._v("对输出进行 2 倍的双线性插值上采样得到 coarse prediction；")]),t._v(" "),s("li",[t._v("依据高频信息挑选出 N 个不确定的点，即物体边缘；")]),t._v(" "),s("li",[t._v("对于不确定的点，获取其特征，特征由低层的细粒度图的特征（fine-grained features）和高层的粗糙预测图的特征（coarse prediction）。")]),t._v(" "),s("li",[t._v("使用 MLP 对特征计算得到新的预测，更新 coarse prediction。MLP 可以看作一个只对不确定点进行运算的多个 conv1x1 组成的小网络。")])]),t._v(" "),s("p",[t._v("选择不确定点的过程，基于这些点应该较密集地分布在高频区域的假设，在图像中自适应地预测分割的点。上采样的过程如下例：")]),t._v(" "),s("p",[s("img",{attrs:{src:n(461),alt:"upsample"}})]),t._v(" "),s("p",[t._v("经过 2 倍双线性插值后，选择最不确定的 N 个点，然后对这些点用 1*1 的卷积核进行像素级的预测。得到一个高分辨率的图像后没继续迭代重复这个过程，直到恢复到原图像大小。")]),t._v(" "),s("p",[t._v("实验结果显示，PointRend 在预测 mask 时十分精细，效果很好。在输出的分辨率更高的情况下，它需要的资源相对少且预测效果更好，并且有抗锯齿的效果。")]),t._v(" "),s("p",[t._v("总的来说，PointRend 具有以下创新点：")]),t._v(" "),s("ol",[s("li",[t._v("提出类似图像渲染的方式，专门对边缘不确定的点进行处理，开创了一个新的思路；")]),t._v(" "),s("li",[t._v("利用迭代上采样的方式，改进 Mask R-CNN；")]),t._v(" "),s("li",[t._v("更低的算力得到了更精细的效果，甚至可以抗锯齿。")])]),t._v(" "),s("h2",{attrs:{id:"阅后思考"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#阅后思考"}},[t._v("#")]),t._v(" 阅后思考")]),t._v(" "),s("p",[t._v("其实总体来看待这篇文章，文中的思路的针对性十分的明显，就是在上采样时，对一些高频位置的点进行特殊的渲染处理，从而使结果更加精细。好像是理所当然，但却是换了一个角度思考问题，从而用很简单的方式高效地解决了一大难题。而计算机视觉领域中非常多的方向存在对于边缘处理不当的问题，其中最明显的就是超分辨算法。因此我在思考，是否可以将本文中的思路应用到超分辨图像当中，针对边缘处理不当的地方像素级地处理。这一点值的往下探究。")]),t._v(" "),s("h2",{attrs:{id:"bibtex"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bibtex"}},[t._v("#")]),t._v(" BibTeX")]),t._v(" "),s("div",{staticClass:"language-latex line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-latex"}},[s("code",[t._v("@InProceedings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("kirillov2019pointrend,\n  title="),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("PointRend"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(": Image Segmentation as Rendering"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(",\n  author="),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Alexander Kirillov and Yuxin Wu and Kaiming He and Ross Girshick"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(",\n  journal="),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("ArXiv:1912.08193"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(",\n  year="),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("2019"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br")])])])}),[],!1,null,null,null);a.default=e.exports}}]);